
# TRAIN PARAMETERS
DATA_LOADER_PATH='data_loader.py'
MODEL_PATH='../../models/roberta-large/'
PROBLEM_TYPE='multi_label_classification'
DO_TRAIN=True
DO_EVAL=True
DO_PREDICT=True
SEED=1
NUM_EPOCHS=5
TRAIN_BATCH_SIZE=8
EVAL_BATCH_SIZE=8
TRAIN_ACC_STEPS=2
EVAL_ACC_STEPS=2
MAX_SEQ_LENGTH=512
PAD_TO_MAX_LEN=True
LEARN_RATE=5e-5
WARMUP=0.06
WEIGHT_DECAY=0.01
SAVE_STEPS=2000
OUTPUT_DIR='./output/'
LOGGING_DIR='./tb/'
LOGGING_STEPS=2000
CACHE_DIR='./.cache'
OVERWRITE_CACHE=False
DDP_FIND_UNUSED_PARAMETERS=True
GPUS_PER_NODE=1
NUM_NODES=1

# SLURM
HPC=false
MASTER_PORT=29401
GPUS_PER_NODE=4
CPUS_PER_NODE=160
NUM_NODES=1
TIME=2-0:00:00 # max allowed job time, format: days-h:mm:ss

